{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8019ba23",
   "metadata": {},
   "source": [
    "## 1. Import Libraries and Initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "29328c0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting groq\n",
      "  Downloading groq-0.33.0-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in c:\\users\\pc\\anaconda3\\envs\\chromadb\\lib\\site-packages (from groq) (4.10.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in c:\\users\\pc\\anaconda3\\envs\\chromadb\\lib\\site-packages (from groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in c:\\users\\pc\\anaconda3\\envs\\chromadb\\lib\\site-packages (from groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in c:\\users\\pc\\anaconda3\\envs\\chromadb\\lib\\site-packages (from groq) (2.10.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\pc\\anaconda3\\envs\\chromadb\\lib\\site-packages (from groq) (1.3.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in c:\\users\\pc\\anaconda3\\envs\\chromadb\\lib\\site-packages (from groq) (4.12.2)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in c:\\users\\pc\\anaconda3\\envs\\chromadb\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\users\\pc\\anaconda3\\envs\\chromadb\\lib\\site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in c:\\users\\pc\\anaconda3\\envs\\chromadb\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\users\\pc\\anaconda3\\envs\\chromadb\\lib\\site-packages (from httpx<1,>=0.23.0->groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\users\\pc\\anaconda3\\envs\\chromadb\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq) (0.14.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\pc\\anaconda3\\envs\\chromadb\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (0.6.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in c:\\users\\pc\\anaconda3\\envs\\chromadb\\lib\\site-packages (from pydantic<3,>=1.9.0->groq) (2.27.2)\n",
      "Downloading groq-0.33.0-py3-none-any.whl (135 kB)\n",
      "Installing collected packages: groq\n",
      "Successfully installed groq-0.33.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc1476b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Libraries imported successfully\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from groq import Groq\n",
    "from dotenv import load_dotenv\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "print(\"✅ Libraries imported successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fd3a8a4",
   "metadata": {},
   "source": [
    "## 2. Initialize Groq API with 70B Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb6f067f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Groq API initialized with model: llama-3.3-70b-versatile\n"
     ]
    }
   ],
   "source": [
    "# Initialize Groq client with 70B model\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "if not api_key:\n",
    "    raise ValueError(\"GROQ_API_KEY not found! Please add it to your .env file\")\n",
    "\n",
    "client = Groq(api_key=api_key)\n",
    "model_name = \"llama-3.3-70b-versatile\"  # Using the powerful 70B model\n",
    "\n",
    "print(f\"✅ Groq API initialized with model: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd4bfe05",
   "metadata": {},
   "source": [
    "## 3. Load Neighborhood Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "200db4a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Loaded 164 neighborhoods\n",
      "📊 Columns: ['Mahalle', 'İlçe', 'Enlem', 'Boylam', 'INDEX_YASAM_KALITESI', 'INDEX_YURUNEBILIRLIK', 'KULTUREL_AKTIVITE_INDEX', 'restaurant', 'library', 'school', 'park', 'atm', 'cafe', 'pharmacy', 'hospital', 'mosque', 'bus_station', 'train_station', 'transit_station', 'Toplam Geçerli Oy', 'Toplam Geçersiz Oy', 'CHP', 'AK PARTİ', 'SAADET', 'VATAN PARTİSİ', 'Nüfus', 'mahalle_uavt', '1980_oncesi', '1980-2000_arasi', '2000_sonrasi', '1-4 kat_arasi', '5-9 kat_arasi', '9-19 kat_arasi', 'mahalle_koy_uavt', 'cok_agir_hasarli_bina_sayisi', 'agir_hasarli_bina_sayisi', 'orta_hasarli_bina_sayisi', 'hafif_hasarli_bina_sayisi', 'can_kaybi_sayisi', 'agir_yarali_sayisi', 'hastanede_tedavi_sayisi', 'hafif_yarali_sayisi', 'dogalgaz_boru_hasari', 'icme_suyu_boru_hasari', 'atik_su_boru_hasari', 'gecici_barinma', 'Avg_Rent_Per_SqM', 'Green_Index', 'Society_Welfare_Index']\n",
      "\n",
      "📋 Sample data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mahalle</th>\n",
       "      <th>İlçe</th>\n",
       "      <th>Enlem</th>\n",
       "      <th>Boylam</th>\n",
       "      <th>INDEX_YASAM_KALITESI</th>\n",
       "      <th>INDEX_YURUNEBILIRLIK</th>\n",
       "      <th>KULTUREL_AKTIVITE_INDEX</th>\n",
       "      <th>restaurant</th>\n",
       "      <th>library</th>\n",
       "      <th>school</th>\n",
       "      <th>...</th>\n",
       "      <th>agir_yarali_sayisi</th>\n",
       "      <th>hastanede_tedavi_sayisi</th>\n",
       "      <th>hafif_yarali_sayisi</th>\n",
       "      <th>dogalgaz_boru_hasari</th>\n",
       "      <th>icme_suyu_boru_hasari</th>\n",
       "      <th>atik_su_boru_hasari</th>\n",
       "      <th>gecici_barinma</th>\n",
       "      <th>Avg_Rent_Per_SqM</th>\n",
       "      <th>Green_Index</th>\n",
       "      <th>Society_Welfare_Index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Balmumcu</td>\n",
       "      <td>Beşiktaş</td>\n",
       "      <td>41.059527</td>\n",
       "      <td>29.015073</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>560</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Bebek</td>\n",
       "      <td>Beşiktaş</td>\n",
       "      <td>41.078970</td>\n",
       "      <td>29.043979</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>560</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kültür</td>\n",
       "      <td>Beşiktaş</td>\n",
       "      <td>41.072961</td>\n",
       "      <td>29.032796</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>560</td>\n",
       "      <td>0.93</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Mahalle      İlçe      Enlem     Boylam  INDEX_YASAM_KALITESI  \\\n",
       "0  Balmumcu  Beşiktaş  41.059527  29.015073                   NaN   \n",
       "1     Bebek  Beşiktaş  41.078970  29.043979                   NaN   \n",
       "2    Kültür  Beşiktaş  41.072961  29.032796                   NaN   \n",
       "\n",
       "   INDEX_YURUNEBILIRLIK  KULTUREL_AKTIVITE_INDEX  restaurant  library  school  \\\n",
       "0                   NaN                      NaN           0        0      13   \n",
       "1                   NaN                      NaN          11        1       4   \n",
       "2                   NaN                      NaN          13        0       2   \n",
       "\n",
       "   ...  agir_yarali_sayisi  hastanede_tedavi_sayisi  hafif_yarali_sayisi  \\\n",
       "0  ...                 NaN                      NaN                  NaN   \n",
       "1  ...                 NaN                      NaN                  NaN   \n",
       "2  ...                 NaN                      NaN                  NaN   \n",
       "\n",
       "   dogalgaz_boru_hasari  icme_suyu_boru_hasari  atik_su_boru_hasari  \\\n",
       "0                   NaN                    NaN                  NaN   \n",
       "1                   NaN                    NaN                  NaN   \n",
       "2                   NaN                    NaN                  NaN   \n",
       "\n",
       "   gecici_barinma  Avg_Rent_Per_SqM  Green_Index  Society_Welfare_Index  \n",
       "0             NaN               560         0.93                    1.0  \n",
       "1             NaN               560         0.93                    1.0  \n",
       "2             NaN               560         0.93                    1.0  \n",
       "\n",
       "[3 rows x 49 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV data\n",
    "csv_path = 'istanbul_mahalle_complete_data.csv'\n",
    "df = pd.read_csv(csv_path)\n",
    "\n",
    "print(f\"✅ Loaded {len(df)} neighborhoods\")\n",
    "print(f\"📊 Columns: {df.columns.tolist()}\")\n",
    "print(f\"\\n📋 Sample data:\")\n",
    "df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "00bca812",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Mahalle', 'İlçe', 'Enlem', 'Boylam', 'INDEX_YASAM_KALITESI',\n",
       "       'INDEX_YURUNEBILIRLIK', 'KULTUREL_AKTIVITE_INDEX', 'restaurant',\n",
       "       'library', 'school', 'park', 'atm', 'cafe', 'pharmacy', 'hospital',\n",
       "       'mosque', 'bus_station', 'train_station', 'transit_station',\n",
       "       'Toplam Geçerli Oy', 'Toplam Geçersiz Oy', 'CHP', 'AK PARTİ', 'SAADET',\n",
       "       'VATAN PARTİSİ', 'Nüfus', 'mahalle_uavt', '1980_oncesi',\n",
       "       '1980-2000_arasi', '2000_sonrasi', '1-4 kat_arasi', '5-9 kat_arasi',\n",
       "       '9-19 kat_arasi', 'mahalle_koy_uavt', 'cok_agir_hasarli_bina_sayisi',\n",
       "       'agir_hasarli_bina_sayisi', 'orta_hasarli_bina_sayisi',\n",
       "       'hafif_hasarli_bina_sayisi', 'can_kaybi_sayisi', 'agir_yarali_sayisi',\n",
       "       'hastanede_tedavi_sayisi', 'hafif_yarali_sayisi',\n",
       "       'dogalgaz_boru_hasari', 'icme_suyu_boru_hasari', 'atik_su_boru_hasari',\n",
       "       'gecici_barinma', 'Avg_Rent_Per_SqM', 'Green_Index',\n",
       "       'Society_Welfare_Index'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c09975ed",
   "metadata": {},
   "source": [
    "## 4. Create Description Generator Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a2233c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Description generator function created\n"
     ]
    }
   ],
   "source": [
    "def generate_mahalle_description(row, client, model_name):\n",
    "    \"\"\"\n",
    "    Generate a rich description for a neighborhood using Groq API\n",
    "    \n",
    "    Args:\n",
    "        row: DataFrame row with neighborhood data\n",
    "        client: Groq client instance\n",
    "        model_name: Model to use for generation\n",
    "        \n",
    "    Returns:\n",
    "        Tuple: (description, keywords)\n",
    "    \"\"\"\n",
    "    \n",
    "    # Extract key features\n",
    "    mahalle = row['Mahalle']\n",
    "    ilce = row['İlçe']\n",
    "    \n",
    "    # Amenities\n",
    "    restaurants = row.get('restaurant', 0)\n",
    "    schools = row.get('school', 0)\n",
    "    parks = row.get('park', 0)\n",
    "    cafes = row.get('cafe', 0)\n",
    "    hospitals = row.get('hospital', 0)\n",
    "    mosques = row.get('mosque', 0)\n",
    "    \n",
    "    # Indices\n",
    "    green_index = row.get('Green_Index', 0)\n",
    "    welfare_index = row.get('Society_Welfare_Index', 0)\n",
    "    rent_per_sqm = row.get('Avg_Rent_Per_SqM', 0)\n",
    "    \n",
    "    # Population\n",
    "    population = row.get('Nüfus', 0)\n",
    "    \n",
    "    # Create prompt for LLM\n",
    "    prompt = f\"\"\"Generate a detailed, information-rich description for this Istanbul neighborhood optimized for semantic search.\n",
    "\n",
    "Neighborhood: {mahalle}, {ilce}\n",
    "\n",
    "Key Statistics:\n",
    "- Quality of Life Index: {row.get('INDEX_YASAM_KALITESI', 0):.2f}\n",
    "- Walkability Index: {row.get('INDEX_YURUNEBILIRLIK', 0):.2f}\n",
    "- Cultural Activity Index: {row.get('KULTUREL_AKTIVITE_INDEX', 0):.2f}\n",
    "- Green Index: {green_index:.2f}\n",
    "- Welfare Index: {welfare_index:.2f}\n",
    "- Population: {population:,.0f}\n",
    "- Rent: {rent_per_sqm:.0f} TL/sqm\n",
    "\n",
    "Amenities:\n",
    "- {restaurants} restaurants, {cafes} cafes\n",
    "- {schools} schools, {row.get('library', 0)} libraries\n",
    "- {parks} parks (green spaces)\n",
    "- {hospitals} hospitals, {row.get('pharmacy', 0)} pharmacies\n",
    "- {mosques} mosques\n",
    "- Transit: {row.get('bus_station', 0)} bus stations, {row.get('train_station', 0)} train stations\n",
    "\n",
    "Building Age Distribution:\n",
    "- Pre-1980: {row.get('1980_oncesi', 0)} buildings\n",
    "- 1980-2000: {row.get('1980-2000_arasi', 0)} buildings\n",
    "- Post-2000: {row.get('2000_sonrasi', 0)} buildings\n",
    "\n",
    "Write a comprehensive 4-5 sentence description that:\n",
    "1. Characterizes the neighborhood's atmosphere and lifestyle\n",
    "2. Mentions who would enjoy living here (families, young professionals, retirees, students)\n",
    "3. Highlights accessibility and transportation\n",
    "4. Notes distinctive features (historic, modern, green, cultural, commercial)\n",
    "5. Includes comparative language (e.g., \"quieter than,\" \"more affordable than,\" \"as vibrant as\")\n",
    "\n",
    "Use natural language that users might search for. Be specific and objective.\n",
    "\n",
    "Description:\"\"\"\n",
    "\n",
    "    try:\n",
    "        # STEP 1: Generate description\n",
    "        chat_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are an expert Istanbul real estate writer who creates engaging neighborhood descriptions.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": prompt\n",
    "                }\n",
    "            ],\n",
    "            model=model_name,\n",
    "            temperature=0.5,\n",
    "            max_tokens=512\n",
    "        )\n",
    "        \n",
    "        description = chat_completion.choices[0].message.content.strip()\n",
    "        \n",
    "        # STEP 2: Generate keywords based on the description\n",
    "        keywords_prompt = f\"\"\"Based on this neighborhood data, generate 8-10 search keywords/phrases that users might use to find this neighborhood.\n",
    "\n",
    "Neighborhood: {mahalle}, {ilce}\n",
    "Description: {description}\n",
    "\n",
    "Include keywords about:\n",
    "- Lifestyle (family-friendly, vibrant nightlife, quiet, etc.)\n",
    "- Demographics (young professionals, students, families)\n",
    "- Character (historic, modern, green, commercial, residential)\n",
    "- Accessibility (metro access, walkable, etc.)\n",
    "- Price range (affordable, mid-range, upscale)\n",
    "\n",
    "Format: comma-separated keywords only, no extra text.\n",
    "\n",
    "Keywords:\"\"\"\n",
    "\n",
    "        keywords_completion = client.chat.completions.create(\n",
    "            messages=[\n",
    "                {\n",
    "                    \"role\": \"system\",\n",
    "                    \"content\": \"You are an expert at creating searchable keywords for neighborhoods.\"\n",
    "                },\n",
    "                {\n",
    "                    \"role\": \"user\",\n",
    "                    \"content\": keywords_prompt\n",
    "                }\n",
    "            ],\n",
    "            model=model_name,\n",
    "            temperature=0.5,  # Less creative for keywords\n",
    "            max_tokens=150\n",
    "        )\n",
    "        \n",
    "        keywords = keywords_completion.choices[0].message.content.strip()\n",
    "        \n",
    "        return description, keywords\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error generating description for {mahalle}: {e}\")\n",
    "        return f\"{mahalle} is a neighborhood in {ilce}, Istanbul.\", \"neighborhood, Istanbul\"\n",
    "\n",
    "print(\"✅ Description generator function created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f5f60c",
   "metadata": {},
   "source": [
    "## 5. Test with One Neighborhood First"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5ef0d949",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🧪 Testing with: Balmumcu, Beşiktaş\n",
      "======================================================================\n",
      "\n",
      "📝 Generated Description:\n",
      "(\"Balmumcu, located in the Beşiktaş district of Istanbul, is a tranquil and family-friendly neighborhood that offers a high quality of life, as evidenced by its perfect Welfare Index score of 1.00. This charming area is ideal for families and retirees who value a peaceful atmosphere, abundant green spaces, and easy access to essential amenities, including hospitals, pharmacies, and schools. With its two parks and numerous green areas, Balmumcu boasts a impressive Green Index score of 0.93, making it a quieter and more natural oasis compared to other Istanbul neighborhoods. While it may not be as vibrant as some of Istanbul's more commercial areas, Balmumcu is still conveniently connected to the city via its bus station, providing a relatively affordable and laid-back lifestyle, with rent prices averaging 560 TL/sqm, which is more affordable than many other neighborhoods in the city. Overall, Balmumcu's unique blend of serenity, natural beauty, and accessibility makes it an attractive option for those seeking a more subdued and family-oriented lifestyle in Istanbul.\", 'family-friendly neighborhoods in Istanbul, quiet neighborhoods in Beşiktaş, affordable areas in Istanbul, green spaces in Beşiktaş, residential areas in Istanbul, family-oriented lifestyles, tranquil neighborhoods in Turkey, laid-back areas in Istanbul, affordable housing in Beşiktaş, peaceful neighborhoods near city center')\n",
      "======================================================================\n",
      "\n",
      "📝 Generated Description:\n",
      "(\"Balmumcu, located in the Beşiktaş district of Istanbul, is a tranquil and family-friendly neighborhood that offers a high quality of life, as evidenced by its perfect Welfare Index score of 1.00. This charming area is ideal for families and retirees who value a peaceful atmosphere, abundant green spaces, and easy access to essential amenities, including hospitals, pharmacies, and schools. With its two parks and numerous green areas, Balmumcu boasts a impressive Green Index score of 0.93, making it a quieter and more natural oasis compared to other Istanbul neighborhoods. While it may not be as vibrant as some of Istanbul's more commercial areas, Balmumcu is still conveniently connected to the city via its bus station, providing a relatively affordable and laid-back lifestyle, with rent prices averaging 560 TL/sqm, which is more affordable than many other neighborhoods in the city. Overall, Balmumcu's unique blend of serenity, natural beauty, and accessibility makes it an attractive option for those seeking a more subdued and family-oriented lifestyle in Istanbul.\", 'family-friendly neighborhoods in Istanbul, quiet neighborhoods in Beşiktaş, affordable areas in Istanbul, green spaces in Beşiktaş, residential areas in Istanbul, family-oriented lifestyles, tranquil neighborhoods in Turkey, laid-back areas in Istanbul, affordable housing in Beşiktaş, peaceful neighborhoods near city center')\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Test with the first neighborhood\n",
    "test_row = df.iloc[0]\n",
    "print(f\"🧪 Testing with: {test_row['Mahalle']}, {test_row['İlçe']}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "test_description = generate_mahalle_description(test_row, client, model_name)\n",
    "print(f\"\\n📝 Generated Description:\\n{test_description}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501d6aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import chromadb\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Check if chroma_db exists\n",
    "if not os.path.exists(\"./chroma_db\"):\n",
    "    print(\"❌ ChromaDB not found!\")\n",
    "    print(\"\udca1 Please run: python vector_db_creation.py\")\n",
    "    raise FileNotFoundError(\"chroma_db directory not found\")\n",
    "\n",
    "print(\"🔍 Attempting to connect to ChromaDB...\")\n",
    "\n",
    "try:\n",
    "    # Try to connect with a fresh client\n",
    "    chroma_client = chromadb.PersistentClient(path=\"./chroma_db\")\n",
    "    \n",
    "    # Try to list collections - this is where the error occurs\n",
    "    collections = chroma_client.list_collections()\n",
    "    \n",
    "    print(f\"✅ Connected to ChromaDB successfully!\")\n",
    "    print(f\"📊 Found {len(collections)} collection(s)\")\n",
    "    \n",
    "    if collections:\n",
    "        collection = collections[0]\n",
    "        print(f\"✅ Using collection: '{collection.name}'\")\n",
    "        print(f\"📊 Total documents: {collection.count()}\")\n",
    "    else:\n",
    "        print(\"⚠️  No collections found in database\")\n",
    "        print(\"💡 Please run: python vector_db_creation.py\")\n",
    "        raise ValueError(\"No collections in ChromaDB\")\n",
    "        \n",
    "except KeyError as e:\n",
    "    print(f\"❌ ChromaDB corruption detected: {e}\")\n",
    "    print(\"\\n\udd27 Your ChromaDB appears to be corrupted (likely version mismatch)\")\n",
    "    print(\"\\n💡 SOLUTION:\")\n",
    "    print(\"   1. Delete the chroma_db folder\")\n",
    "    print(\"   2. Run: python vector_db_creation.py\")\n",
    "    print(\"   3. Then come back and run this cell again\")\n",
    "    print(\"\\n📝 To delete, run in terminal:\")\n",
    "    print(\"   Remove-Item -Recurse -Force chroma_db\")\n",
    "    raise\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Unexpected error: {type(e).__name__}: {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d22ad3f",
   "metadata": {},
   "source": [
    "### 🔧 Fix Corrupted ChromaDB (Run this if you got the KeyError above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6e559fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ONLY RUN THIS IF YOU GOT THE KeyError ABOVE!\n",
    "# This will delete and recreate your vector database\n",
    "\n",
    "import shutil\n",
    "import os\n",
    "\n",
    "# Backup old database (just in case)\n",
    "if os.path.exists(\"./chroma_db\"):\n",
    "    print(\"🗑️  Removing corrupted ChromaDB...\")\n",
    "    shutil.rmtree(\"./chroma_db\")\n",
    "    print(\"✅ Old database removed\")\n",
    "else:\n",
    "    print(\"ℹ️  No existing database found\")\n",
    "\n",
    "# Now recreate it\n",
    "print(\"\\n🔨 Recreating vector database...\")\n",
    "print(\"💡 Running vector_db_creation.py...\")\n",
    "\n",
    "# Run the creation script\n",
    "import subprocess\n",
    "result = subprocess.run(\n",
    "    [\"python\", \"vector_db_creation.py\"],\n",
    "    capture_output=True,\n",
    "    text=True\n",
    ")\n",
    "\n",
    "print(result.stdout)\n",
    "if result.returncode == 0:\n",
    "    print(\"✅ Vector database recreated successfully!\")\n",
    "    print(\"💡 Now go back and run the cell above again\")\n",
    "else:\n",
    "    print(f\"❌ Error: {result.stderr}\")\n",
    "    raise RuntimeError(\"Failed to recreate vector database\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5676e7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all embeddings from ChromaDB\n",
    "results = collection.get(\n",
    "    include=['embeddings', 'metadatas']\n",
    ")\n",
    "\n",
    "embeddings = np.array(results['embeddings'])\n",
    "metadatas = results['metadatas']\n",
    "\n",
    "print(f\"✅ Retrieved {len(embeddings)} embeddings\")\n",
    "print(f\"📊 Embedding dimension: {embeddings.shape[1]}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "496e96e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate pairwise cosine similarity\n",
    "print(\"🔍 Calculating pairwise similarity matrix...\")\n",
    "sim_matrix = cosine_similarity(embeddings)\n",
    "\n",
    "print(f\"✅ Similarity matrix shape: {sim_matrix.shape}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c4618d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average similarity (excluding diagonal - self-similarity)\n",
    "n = len(embeddings)\n",
    "avg_similarity = (sim_matrix.sum() - n) / (n * (n - 1))\n",
    "\n",
    "print(\"📊 EMBEDDING DIVERSITY ANALYSIS\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Average pairwise similarity: {avg_similarity:.3f}\")\n",
    "print()\n",
    "print(\"📈 Interpretation:\")\n",
    "if avg_similarity < 0.3:\n",
    "    print(\"   ✅ EXCELLENT - Very diverse embeddings, neighborhoods are highly distinct\")\n",
    "elif avg_similarity < 0.5:\n",
    "    print(\"   ✅ GOOD - Diverse embeddings, neighborhoods are distinguishable\")\n",
    "elif avg_similarity < 0.7:\n",
    "    print(\"   ⚠️  MODERATE - Some overlap, but still usable\")\n",
    "else:\n",
    "    print(\"   ❌ BAD - Too similar, neighborhoods are not well-differentiated\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307b3124",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional statistics\n",
    "print(\"📊 DETAILED STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get upper triangle (excluding diagonal)\n",
    "upper_triangle = sim_matrix[np.triu_indices_from(sim_matrix, k=1)]\n",
    "\n",
    "print(f\"Min similarity: {upper_triangle.min():.3f}\")\n",
    "print(f\"Max similarity: {upper_triangle.max():.3f}\")\n",
    "print(f\"Median similarity: {np.median(upper_triangle):.3f}\")\n",
    "print(f\"Std deviation: {upper_triangle.std():.3f}\")\n",
    "print()\n",
    "\n",
    "# Distribution\n",
    "print(\"📊 Similarity Distribution:\")\n",
    "print(f\"   < 0.3 (Very different): {(upper_triangle < 0.3).sum():,} pairs ({(upper_triangle < 0.3).sum()/len(upper_triangle)*100:.1f}%)\")\n",
    "print(f\"   0.3-0.5 (Different): {((upper_triangle >= 0.3) & (upper_triangle < 0.5)).sum():,} pairs ({((upper_triangle >= 0.3) & (upper_triangle < 0.5)).sum()/len(upper_triangle)*100:.1f}%)\")\n",
    "print(f\"   0.5-0.7 (Similar): {((upper_triangle >= 0.5) & (upper_triangle < 0.7)).sum():,} pairs ({((upper_triangle >= 0.5) & (upper_triangle < 0.7)).sum()/len(upper_triangle)*100:.1f}%)\")\n",
    "print(f\"   > 0.7 (Very similar): {(upper_triangle >= 0.7).sum():,} pairs ({(upper_triangle >= 0.7).sum()/len(upper_triangle)*100:.1f}%)\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610ea6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most similar pairs (potential duplicates or very similar neighborhoods)\n",
    "print(\"🔍 TOP 10 MOST SIMILAR NEIGHBORHOOD PAIRS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get indices of top similarities (excluding diagonal)\n",
    "np.fill_diagonal(sim_matrix, -1)  # Exclude self-similarity\n",
    "top_indices = np.argsort(sim_matrix.flatten())[-10:][::-1]\n",
    "top_pairs = np.unravel_index(top_indices, sim_matrix.shape)\n",
    "\n",
    "for i, (idx1, idx2) in enumerate(zip(top_pairs[0], top_pairs[1]), 1):\n",
    "    similarity = sim_matrix[idx1, idx2]\n",
    "    mahalle1 = metadatas[idx1].get('mahalle', 'Unknown')\n",
    "    ilce1 = metadatas[idx1].get('ilce', 'Unknown')\n",
    "    mahalle2 = metadatas[idx2].get('mahalle', 'Unknown')\n",
    "    ilce2 = metadatas[idx2].get('ilce', 'Unknown')\n",
    "    \n",
    "    print(f\"{i}. {mahalle1}, {ilce1} ↔ {mahalle2}, {ilce2}\")\n",
    "    print(f\"   Similarity: {similarity:.3f}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55320497",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most diverse pairs (very different neighborhoods)\n",
    "print(\"🔍 TOP 10 MOST DIVERSE NEIGHBORHOOD PAIRS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Get indices of lowest similarities\n",
    "bottom_indices = np.argsort(sim_matrix.flatten())[:10]\n",
    "bottom_pairs = np.unravel_index(bottom_indices, sim_matrix.shape)\n",
    "\n",
    "for i, (idx1, idx2) in enumerate(zip(bottom_pairs[0], bottom_pairs[1]), 1):\n",
    "    # Skip if it's the diagonal we marked as -1\n",
    "    if sim_matrix[idx1, idx2] < 0:\n",
    "        continue\n",
    "        \n",
    "    similarity = sim_matrix[idx1, idx2]\n",
    "    mahalle1 = metadatas[idx1].get('mahalle', 'Unknown')\n",
    "    ilce1 = metadatas[idx1].get('ilce', 'Unknown')\n",
    "    mahalle2 = metadatas[idx2].get('mahalle', 'Unknown')\n",
    "    ilce2 = metadatas[idx2].get('ilce', 'Unknown')\n",
    "    \n",
    "    print(f\"{i}. {mahalle1}, {ilce1} ↔ {mahalle2}, {ilce2}\")\n",
    "    print(f\"   Similarity: {similarity:.3f} (very different!)\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a722530",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize similarity distribution\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "# Histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(upper_triangle, bins=50, edgecolor='black', alpha=0.7)\n",
    "plt.axvline(avg_similarity, color='red', linestyle='--', linewidth=2, label=f'Mean: {avg_similarity:.3f}')\n",
    "plt.xlabel('Cosine Similarity')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Pairwise Similarities')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# Box plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.boxplot(upper_triangle, vert=True)\n",
    "plt.ylabel('Cosine Similarity')\n",
    "plt.title('Similarity Statistics')\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"✅ Visualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e799be91",
   "metadata": {},
   "source": [
    "## 6. Generate Descriptions for All Neighborhoods\n",
    "\n",
    "⚠️ **Note:** This will make API calls for all neighborhoods. With 164 neighborhoods, this will take some time.\n",
    "\n",
    "Groq API rate limits:\n",
    "- Free tier: ~30 requests per minute\n",
    "- So for 164 neighborhoods: ~5-10 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "67250ba5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Generating descriptions for 164 neighborhoods...\n",
      "======================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  12%|█▏        | 19/164 [00:32<04:09,  1.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Processed 20/164 neighborhoods. Pausing 2 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  24%|██▍       | 39/164 [01:07<03:31,  1.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Processed 40/164 neighborhoods. Pausing 2 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  36%|███▌      | 59/164 [01:41<02:58,  1.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Processed 60/164 neighborhoods. Pausing 2 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  48%|████▊     | 79/164 [02:19<02:19,  1.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Processed 80/164 neighborhoods. Pausing 2 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  60%|██████    | 99/164 [02:53<01:46,  1.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Processed 100/164 neighborhoods. Pausing 2 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  73%|███████▎  | 119/164 [03:30<01:16,  1.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Processed 120/164 neighborhoods. Pausing 2 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  85%|████████▍ | 139/164 [04:31<00:41,  1.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Processed 140/164 neighborhoods. Pausing 2 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating:  97%|█████████▋| 159/164 [05:14<00:13,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Processed 160/164 neighborhoods. Pausing 2 seconds...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating: 100%|██████████| 164/164 [05:41<00:00,  2.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "\n",
      "✅ Generation complete!\n",
      "📊 Successfully generated: 164/164\n",
      "❌ Failed: 0\n",
      "✅ Descriptions and keywords added to DataFrame\n",
      "📊 DataFrame shape: (164, 51)\n",
      "\n",
      "📋 Sample descriptions:\n",
      "======================================================================\n",
      "\n",
      "🏘️ Balmumcu, Beşiktaş\n",
      "📝 Description: Balmumcu, located in the Beşiktaş district of Istanbul, is a tranquil and family-friendly neighborhood that offers a high quality of life, as evidenced by its perfect Welfare Index score of 1.00. This...\n",
      "🏷️ Keywords: family-friendly neighborhoods in Istanbul, quiet neighborhoods in Beşiktaş, affordable areas in Istanbul, green spaces in Balmumcu, residential areas in Beşiktaş, tranquil lifestyle in Istanbul, family-friendly areas in Turkey, affordable housing in Beşiktaş, peaceful neighborhoods in Istanbul, mid-range rent in Istanbul\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "🏘️ Bebek, Beşiktaş\n",
      "📝 Description: Bebek, located in the Beşiktaş district, is a charming and upscale neighborhood that offers a unique blend of natural beauty and urban convenience, making it an ideal destination for families and youn...\n",
      "🏷️ Keywords: family-friendly neighborhoods in Istanbul, upscale areas in Beşiktaş, quiet neighborhoods in Istanbul, young professional neighborhoods, green spaces in Istanbul, affordable luxury neighborhoods, residential areas in Beşiktaş, walkable neighborhoods in Istanbul, historic neighborhoods with modern amenities, mid-range rent in Istanbul, vibrant yet quiet neighborhoods.\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "🏘️ Kültür, Beşiktaş\n",
      "📝 Description: Kültür, located in the Beşiktaş district of Istanbul, offers a unique blend of tranquility and convenience, making it an ideal neighborhood for families and young professionals seeking a relaxed atmos...\n",
      "🏷️ Keywords: family-friendly neighborhoods in Istanbul, quiet neighborhoods in Beşiktaş, green neighborhoods in Istanbul, affordable residential areas in Istanbul, young professional neighborhoods in Beşiktaş, walkable neighborhoods in Istanbul, mid-range neighborhoods in Istanbul, peaceful neighborhoods in Istanbul, family-friendly areas in Beşiktaş, tranquil neighborhoods in Istanbul\n",
      "----------------------------------------------------------------------\n",
      "\n",
      "💾 Saved to: neighborhoods_with_descriptions.csv\n",
      "💾 Backup saved to: neighborhoods_backup_20251026_021541.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Generate descriptions AND keywords for all neighborhoods\n",
    "descriptions = []\n",
    "keywords_list = []  # Add this!\n",
    "failed_count = 0\n",
    "\n",
    "print(f\"🚀 Generating descriptions for {len(df)} neighborhoods...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "for idx, row in tqdm(df.iterrows(), total=len(df), desc=\"Generating\"):\n",
    "    try:\n",
    "        # Unpack both return values\n",
    "        description, keywords = generate_mahalle_description(row, client, model_name)\n",
    "        descriptions.append(description)\n",
    "        keywords_list.append(keywords)  # Store keywords too!\n",
    "        \n",
    "        # Rate limiting - be nice to the API\n",
    "        if (idx + 1) % 20 == 0:  # Every 20 requests\n",
    "            print(f\"\\n✅ Processed {idx + 1}/{len(df)} neighborhoods. Pausing 2 seconds...\")\n",
    "            time.sleep(2)\n",
    "        else:\n",
    "            time.sleep(0.3)  # Increase delay (you're making 2 API calls now)\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Failed for row {idx}: {e}\")\n",
    "        descriptions.append(f\"{row['Mahalle']} is a neighborhood in {row['İlçe']}, Istanbul.\")\n",
    "        keywords_list.append(\"neighborhood, Istanbul\")  # Default keywords\n",
    "        failed_count += 1\n",
    "        time.sleep(1)  # Wait longer after error\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\n✅ Generation complete!\")\n",
    "print(f\"📊 Successfully generated: {len(descriptions) - failed_count}/{len(df)}\")\n",
    "print(f\"❌ Failed: {failed_count}\")\n",
    "\n",
    "# Add BOTH columns to DataFrame\n",
    "df['Description'] = descriptions\n",
    "df['Keywords'] = keywords_list  # Add keywords column!\n",
    "\n",
    "print(\"✅ Descriptions and keywords added to DataFrame\")\n",
    "print(f\"📊 DataFrame shape: {df.shape}\")\n",
    "print(f\"\\n📋 Sample descriptions:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Show a few examples with keywords\n",
    "for i in range(min(3, len(df))):\n",
    "    print(f\"\\n🏘️ {df.iloc[i]['Mahalle']}, {df.iloc[i]['İlçe']}\")\n",
    "    print(f\"📝 Description: {df.iloc[i]['Description'][:200]}...\")  # First 200 chars\n",
    "    print(f\"🏷️ Keywords: {df.iloc[i]['Keywords']}\")\n",
    "    print(\"-\" * 70)\n",
    "\n",
    "# SAVE TO CSV\n",
    "output_file = 'neighborhoods_with_descriptions.csv'\n",
    "df.to_csv(output_file, index=False, encoding='utf-8-sig')  # utf-8-sig for Turkish characters\n",
    "print(f\"\\n💾 Saved to: {output_file}\")\n",
    "\n",
    "# Optional: Save a backup with timestamp\n",
    "from datetime import datetime\n",
    "backup_file = f'neighborhoods_backup_{datetime.now().strftime(\"%Y%m%d_%H%M%S\")}.csv'\n",
    "df.to_csv(backup_file, index=False, encoding='utf-8-sig')\n",
    "print(f\"💾 Backup saved to: {backup_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f964d4b6",
   "metadata": {},
   "source": [
    "## 7. Add Descriptions to DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbdba7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add descriptions as a new column\n",
    "df['Description'] = descriptions\n",
    "\n",
    "print(\"✅ Descriptions added to DataFrame\")\n",
    "print(f\"📊 DataFrame shape: {df.shape}\")\n",
    "print(f\"\\n📋 Sample descriptions:\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Show a few examples\n",
    "for i in range(min(3, len(df))):\n",
    "    print(f\"\\n🏘️ {df.iloc[i]['Mahalle']}, {df.iloc[i]['İlçe']}\")\n",
    "    print(f\"📝 {df.iloc[i]['Description']}\")\n",
    "\n",
    "    print(\"-\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b832b5c2",
   "metadata": {},
   "source": [
    "## 8. Save to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e57cc39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the enriched data\n",
    "output_path = 'istanbul_mahalle_complete_data_with_descriptions_70B.csv'\n",
    "df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "\n",
    "print(f\"✅ Data saved to: {output_path}\")\n",
    "print(f\"📊 Total rows: {len(df)}\")\n",
    "print(f\"📊 Total columns: {len(df.columns)}\")\n",
    "print(f\"\\n🎉 All done! You can now use this enriched dataset with rich descriptions.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b143431d",
   "metadata": {},
   "source": [
    "## 9. (Optional) View Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722994c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistics about the descriptions\n",
    "print(\"📊 Description Statistics\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Description lengths\n",
    "df['Description_Length'] = df['Description'].str.len()\n",
    "print(f\"Average description length: {df['Description_Length'].mean():.0f} characters\")\n",
    "print(f\"Shortest description: {df['Description_Length'].min()} characters\")\n",
    "print(f\"Longest description: {df['Description_Length'].max()} characters\")\n",
    "\n",
    "# Words per description\n",
    "df['Description_Words'] = df['Description'].str.split().str.len()\n",
    "print(f\"\\nAverage words per description: {df['Description_Words'].mean():.0f} words\")\n",
    "print(f\"Shortest: {df['Description_Words'].min()} words\")\n",
    "print(f\"Longest: {df['Description_Words'].max()} words\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"🎯 Ready to use for vector database creation!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chromadb",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
